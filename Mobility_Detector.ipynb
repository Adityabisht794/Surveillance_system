{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Automated Motion Recorder<h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background Subtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started saving motion-detected video: motion_recordings\\Web Cam12-12-2024_14-50-04.avi\n",
      "Motion-detected video saved at: motion_recordings\\Web Cam12-12-2024_14-50-04.avi\n"
     ]
    }
   ],
   "source": [
    "# Initialize the video capture\n",
    "video1 = cv2.VideoCapture(0)\n",
    "\n",
    "# Directory to save the output video\n",
    "save_dir = \"motion_recordings\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Initialize variables for video recording\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "unix_time = time.time()\n",
    "\n",
    "# Convert the Unix timestamp to a datetime object\n",
    "date_time = datetime.fromtimestamp(unix_time)\n",
    "\n",
    "# Format the datetime object as dd-mm-yyyy_HH-MM-SS\n",
    "formatted_date_time = date_time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "filename = os.path.join(save_dir, f\"Web Cam{formatted_date_time}.avi\")\n",
    "out = None\n",
    "\n",
    "\n",
    "# Initialize the background subtractor\n",
    "backgroundObject = cv2.createBackgroundSubtractorMOG2(\n",
    "    varThreshold=30, detectShadows=True, history=70\n",
    ")\n",
    "\n",
    "# Kernel for morphological operations\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = video1.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply the background subtractor\n",
    "    fgmask = backgroundObject.apply(frame)\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "    fgmask = cv2.dilate(fgmask, kernel, iterations=2)\n",
    "\n",
    "    # Detect contours in the frame\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If motion is detected, process the frame\n",
    "    for contour in contours:\n",
    "        # Ignore small contours to avoid noise\n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "\n",
    "        # Get the bounding box coordinates for the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Draw a green rectangle around the motion area\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    # If motion is detected, add timestamp and save the video\n",
    "    if len(contours) > 0:\n",
    "        # Add timestamp to the frame\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Motion detected: {timestamp}\",\n",
    "            (10, 20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.75,\n",
    "            (255, 0, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        # Initialize the video writer if not already started\n",
    "        if out is None:\n",
    "            out = cv2.VideoWriter(\n",
    "                filename, fourcc, 30.0, (frame.shape[1], frame.shape[0])\n",
    "            )\n",
    "            print(f\"Started saving motion-detected video: {filename}\")\n",
    "\n",
    "        # Write the motion-detected frame to the video\n",
    "        out.write(frame)\n",
    "\n",
    "    # Resize both frames to equal dimensions for stacking\n",
    "    frame_resized = cv2.resize(frame, (640, 480))\n",
    "    fgmask_resized = cv2.resize(fgmask, (640, 480))\n",
    "\n",
    "    # Convert `fgmask` to a 3-channel image for stacking\n",
    "    fgmask_color = cv2.cvtColor(fgmask_resized, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Stack the original frame and the foreground mask side by side\n",
    "    stacked_frames = np.hstack((frame_resized, fgmask_color))\n",
    "\n",
    "    # Display the stacked frames\n",
    "    cv2.imshow(\"Motion Detection (Left: Frame, Right: Mask)\", stacked_frames)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "video1.release()\n",
    "if out:\n",
    "    out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Motion-detected video saved at: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration using External Camera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started saving motion-detected video: motion_recordings\\External Camera12-12-2024_14-50-52.avi\n",
      "Motion-detected video saved at: motion_recordings\\External Camera12-12-2024_14-50-52.avi\n"
     ]
    }
   ],
   "source": [
    "# Initialize the video capture\n",
    "# http://100.83.244.243:8080/\n",
    "\n",
    "\n",
    "video1 = cv2.VideoCapture(\"http://100.83.244.243:8080/video\")\n",
    "\n",
    "# Directory to save the output video\n",
    "\n",
    "save_dir = \"motion_recordings\"\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "\n",
    "\n",
    "\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize variables for video recording\n",
    "\n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "\n",
    "\n",
    "unix_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# Convert the Unix timestamp to a datetime object\n",
    "\n",
    "\n",
    "\n",
    "date_time = datetime.fromtimestamp(unix_time)\n",
    "\n",
    "\n",
    "\n",
    "# Format the datetime object as dd-mm-yyyy_HH-MM-SS\n",
    "\n",
    "\n",
    "\n",
    "formatted_date_time = date_time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "filename = os.path.join(save_dir, f\"External Camera{formatted_date_time}.avi\")\n",
    "\n",
    "\n",
    "\n",
    "out = None\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the background subtractor\n",
    "\n",
    "\n",
    "\n",
    "backgroundObject = cv2.createBackgroundSubtractorMOG2(\n",
    "\n",
    "\n",
    "\n",
    "    varThreshold=100, detectShadows=True, history=60\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Kernel for morphological operations\n",
    "\n",
    "\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "\n",
    "\n",
    "    # Read a new frame\n",
    "\n",
    "\n",
    "\n",
    "    ret, frame = video1.read()\n",
    "\n",
    "\n",
    "\n",
    "    if not ret:\n",
    "\n",
    "\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Apply the background subtractor\n",
    "\n",
    "\n",
    "\n",
    "    fgmask = backgroundObject.apply(frame)\n",
    "\n",
    "\n",
    "\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=2)\n",
    "\n",
    "\n",
    "\n",
    "    fgmask = cv2.dilate(fgmask, kernel, iterations=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Detect contours in the frame\n",
    "\n",
    "\n",
    "\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # If motion is detected, process the frame\n",
    "\n",
    "\n",
    "\n",
    "    for contour in contours:\n",
    "\n",
    "\n",
    "\n",
    "        # Ignore small contours to avoid noise\n",
    "\n",
    "\n",
    "\n",
    "        if cv2.contourArea(contour) < 2000:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Get the bounding box coordinates for the contour\n",
    "\n",
    "\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Draw a green rectangle around the motion area\n",
    "\n",
    "\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # If motion is detected, add timestamp and save the video\n",
    "\n",
    "\n",
    "\n",
    "    if len(contours) > 0:\n",
    "\n",
    "\n",
    "\n",
    "        # Add timestamp to the frame\n",
    "\n",
    "\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "\n",
    "\n",
    "\n",
    "            f\"Motion detected: {timestamp}\",\n",
    "\n",
    "\n",
    "\n",
    "            (10, 20),\n",
    "\n",
    "\n",
    "\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\n",
    "\n",
    "\n",
    "            0.75,\n",
    "\n",
    "\n",
    "\n",
    "            (255, 0, 0),\n",
    "\n",
    "            2,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Initialize the video writer if not already started\n",
    "\n",
    "\n",
    "\n",
    "        if out is None:\n",
    "\n",
    "\n",
    "\n",
    "            out = cv2.VideoWriter(\n",
    "\n",
    "\n",
    "\n",
    "                filename, fourcc, 20.0, (frame.shape[1], frame.shape[0])\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Started saving motion-detected video: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Write the motion-detected frame to the video\n",
    "\n",
    "\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Resize both frames to equal dimensions for stacking\n",
    "\n",
    "\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (640, 480))\n",
    "\n",
    "\n",
    "\n",
    "    fgmask_resized = cv2.resize(fgmask, (640, 480))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Convert `fgmask` to a 3-channel image for stacking\n",
    "\n",
    "\n",
    "\n",
    "    fgmask_color = cv2.cvtColor(fgmask_resized, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Stack the original frame and the foreground mask side by side\n",
    "\n",
    "\n",
    "\n",
    "    stacked_frames = np.hstack((frame_resized, fgmask_color))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Display the stacked frames\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Motion Detection on Remote Camera)\", frame_resized)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Press 'q' to exit\n",
    "\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "\n",
    "\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Release resources\n",
    "\n",
    "\n",
    "\n",
    "video1.release()\n",
    "\n",
    "\n",
    "\n",
    "if out:\n",
    "    out.release()\n",
    "\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Motion-detected video saved at: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
